{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../dataset\"\n",
    "INDEX_FIELD = \"timestamp\"\n",
    "DATA_FIELD = \"num_request\"\n",
    "\n",
    "PROACTIVE_RESULT_ROOT=\"proactive_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_file_list(dataset_path: str) -> List[str]:\n",
    "    return os.listdir(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(csv_path: str,index_field:str,data_field:str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df[index_field].to_numpy(), df[data_field].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_candidate_cpds(path: str) -> List[int]:\n",
    "    candidate_cpds = None\n",
    "    with open(path, \"r\") as f:\n",
    "        candidate_cpds = json.load(f)\n",
    "    return candidate_cpds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator:\n",
    "    def __init__(self, workload: np.ndarray, capacity_per_pod: float, sla: float, fluctuation: float, t_cooldown: int = 1) -> None:\n",
    "        self.t = 0\n",
    "        self.sla = sla\n",
    "        self.upper_sla = sla+fluctuation\n",
    "        self.lower_sla = sla-fluctuation\n",
    "        self.workload = workload\n",
    "        self.capaciy_per_pod = capacity_per_pod\n",
    "        self.t_cooldown = t_cooldown\n",
    "        self.r_cpu_list = []\n",
    "        self.n_pod_list = []\n",
    "        self.n_scale = 0\n",
    "        self.workload_list = []\n",
    "\n",
    "    def run(self):\n",
    "        n_pod = int(np.ceil(self.workload[0]/(self.sla*self.capaciy_per_pod)))\n",
    "        t_last_scale = -1\n",
    "        while self.t < len(self.workload)-2:\n",
    "            current_workload = self.workload[self.t]\n",
    "            self.workload_list.append(current_workload)\n",
    "            future_workload = np.average([self.workload[self.t+1], self.workload[self.t+2]])\n",
    "            if self.t-t_last_scale > self.t_cooldown:\n",
    "                target_n_pod = int(np.ceil(future_workload/(self.sla*self.capaciy_per_pod)))\n",
    "                if target_n_pod != n_pod:\n",
    "                    n_pod = target_n_pod\n",
    "                    t_last_scale = self.t\n",
    "                    self.n_scale += 1\n",
    "            r_cpu = 1.0*current_workload/(n_pod*self.capaciy_per_pod)\n",
    "            self.r_cpu_list.append(r_cpu)\n",
    "            self.n_pod_list.append(n_pod)\n",
    "            self.t += 1\n",
    "    \n",
    "    def r_sla_violate(self):\n",
    "        return 1.0*(len(np.where(np.array(self.r_cpu_list) > self.upper_sla)[0])+len(np.where(np.array(self.r_cpu_list) < self.lower_sla)[0]))/len(self.r_cpu_list)\n",
    "    \n",
    "    def r_sla_violate_upper(self):\n",
    "        return 1.0*(len(np.where(np.array(self.r_cpu_list) > self.upper_sla)[0]))/len(self.r_cpu_list)\n",
    "    \n",
    "    def r_sla_violate_lower(self):\n",
    "        return 1.0*(len(np.where(np.array(self.r_cpu_list) < self.lower_sla)[0]))/len(self.r_cpu_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_dir(dir: str, path: str):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(dir, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "workload_to_skip_list = [\"workload_1998-06-13\", \"workload_1998-06-14\", \"workload_1998-06-20\", \"workload_1998-06-21\", \"workload_1998-06-27\", \"workload_1998-06-28\",\"workload_1998-07-04\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read workload_1998-06-10.csv\n",
      "read workload_1998-06-11.csv\n",
      "read workload_1998-06-12.csv\n",
      "read workload_1998-06-15.csv\n",
      "read workload_1998-06-16.csv\n",
      "read workload_1998-06-17.csv\n",
      "read workload_1998-06-18.csv\n",
      "read workload_1998-06-19.csv\n",
      "read workload_1998-06-22.csv\n",
      "read workload_1998-06-23.csv\n",
      "read workload_1998-06-24.csv\n",
      "read workload_1998-06-25.csv\n",
      "read workload_1998-06-26.csv\n",
      "read workload_1998-06-29.csv\n",
      "read workload_1998-06-30.csv\n",
      "read workload_1998-07-03.csv\n",
      "read workload_1998-07-07.csv\n",
      "read workload_1998-07-08.csv\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(PROACTIVE_RESULT_ROOT):\n",
    "    os.makedirs(PROACTIVE_RESULT_ROOT)\n",
    "data_file_list = get_data_file_list(DATASET_PATH)\n",
    "x, y = [], []\n",
    "n_scale_dict = {}\n",
    "r_cpu_dict = {}\n",
    "n_pod_dict = {}\n",
    "workload_dict = {}\n",
    "r_sla_vio_dict={}\n",
    "r_sla_vio_upper_dict={}\n",
    "r_sla_vio_lower_dict={}\n",
    "for file_name in data_file_list:\n",
    "    workload_name = file_name.split(\".\")[0]\n",
    "    if workload_name in workload_to_skip_list:\n",
    "        continue\n",
    "    print(\"read %s\" % (file_name))\n",
    "    np_index, np_data = read_dataset(os.path.join(DATASET_PATH, file_name), INDEX_FIELD, DATA_FIELD)\n",
    "    np_data = np.floor(np_data/10.0)\n",
    "    simulator = Simulator(workload=np_data, capacity_per_pod=2500, sla=0.5, fluctuation=0.1, t_cooldown=1)\n",
    "    simulator.run()\n",
    "    n_scale_dict[workload_name] = simulator.n_scale\n",
    "    r_cpu_dict[workload_name] = simulator.r_cpu_list\n",
    "    n_pod_dict[workload_name] = simulator.n_pod_list\n",
    "    workload_dict[workload_name] = simulator.workload_list\n",
    "    r_sla_vio_dict[workload_name]=simulator.r_sla_violate()\n",
    "    r_sla_vio_upper_dict[workload_name]=simulator.r_sla_violate_upper()\n",
    "    r_sla_vio_lower_dict[workload_name]=simulator.r_sla_violate_lower()\n",
    "dump_dir(n_scale_dict, os.path.join(PROACTIVE_RESULT_ROOT, \"n_scale.json\"))\n",
    "dump_dir(r_cpu_dict, os.path.join(PROACTIVE_RESULT_ROOT, \"r_cpu.json\"))\n",
    "dump_dir(n_pod_dict, os.path.join(PROACTIVE_RESULT_ROOT, \"n_pod.json\"))\n",
    "dump_dir(workload_dict, os.path.join(PROACTIVE_RESULT_ROOT, \"workload.json\"))\n",
    "dump_dir(r_sla_vio_dict, os.path.join(PROACTIVE_RESULT_ROOT, \"r_sla_violate.json\"))\n",
    "dump_dir(r_sla_vio_upper_dict, os.path.join(PROACTIVE_RESULT_ROOT, \"r_sla_violate_upper.json\"))\n",
    "dump_dir(r_sla_vio_lower_dict, os.path.join(PROACTIVE_RESULT_ROOT, \"r_sla_violate_lower.json\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoscaling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
