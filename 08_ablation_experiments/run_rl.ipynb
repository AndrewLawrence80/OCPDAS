{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import json\n",
    "from train_utils import OffPolicyTrainer\n",
    "from world_cup_env import WorldCupEnv\n",
    "from agent import DoubleDQNAgent\n",
    "\n",
    "font = {'size': 16}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"signal\"\n",
    "N_LOOKBACK = 4\n",
    "N_PREDICT = 2\n",
    "\n",
    "REWARD_SAVE_ROOT=\"rl_reward\"\n",
    "WEIGHT_SAVE_ROOT=\"rl_weight\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_file_list(dataset_path: str) -> List[str]:\n",
    "    return os.listdir(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(csv_path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df[\"signal\"].to_numpy(), df[\"is_change_point\"].to_numpy(dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(REWARD_SAVE_ROOT):\n",
    "        os.makedirs(REWARD_SAVE_ROOT)\n",
    "if not os.path.exists(WEIGHT_SAVE_ROOT):\n",
    "    os.makedirs(WEIGHT_SAVE_ROOT)\n",
    "state_list = None\n",
    "action_list = None\n",
    "env = None\n",
    "agent = DoubleDQNAgent(2)\n",
    "trainer = OffPolicyTrainer(env, agent, num_episodes=150, replay_buffer_size=128, batch_size=32, discount_factor=0.9, epsilon_start=0.5, epsilon_end=0.1, epsilon_step=20, learning_rate_start=1e-3, learning_rate_end=1e-4, learning_rate_step=100, tau=0.05)\n",
    "for file_name in get_data_file_list(DATASET_PATH):\n",
    "    signal, is_change_point = read_dataset(os.path.join(DATASET_PATH, file_name))\n",
    "    # use part of the data to train rl agent, you can also use the whole dataset.\n",
    "    signal=signal[:int(0.7*len(signal))]\n",
    "    is_change_point=is_change_point[:int(0.7*len(is_change_point))]\n",
    "    candidate_cpds = np.where(is_change_point == 1)[0]\n",
    "    signal = signal/10.0\n",
    "    workload_diff = np.diff(signal).reshape((-1, 1))\n",
    "    env = WorldCupEnv(workload_diff, candidate_cpds, N_LOOKBACK, N_PREDICT)\n",
    "    trainer.set_env(env)\n",
    "    _, reward_per_episode = trainer.train()\n",
    "    state_list, action_list = trainer.eval()\n",
    "    with open(os.path.join(REWARD_SAVE_ROOT, file_name.split(\".\")[0]+\".json\"), \"w\") as f:\n",
    "        json.dump(reward_per_episode, f, indent=4)\n",
    "    agent.save(os.path.join(WEIGHT_SAVE_ROOT, file_name.split(\".\")[0]+\".pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoscaling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
